% !TEX root = main.tex
% !TEX spellcheck = en-US

\section{Non-malleability of Sonic}
\label{sec:sonic}

\markulfdone{22.04}{I prefer the notation $Pr[\chi \gets \FF_q; \chi' \gets \adv( ...): \chi=\chi']$ as one can start reading at the left. But I will let that one go and will admit that it's a question of taste and it might be an aquired taste. }

\subsection{Preliminaries}
\begin{definition}[$(q_1, q_2)\mhyph\ldlog$ assumption]\label{def:ldlog}
  Let $\adv$ be a $\ppt$ adversary that gets as input
  $\gone{\chi^{-q_1}, \ldots, 1, \ldots, \chi^{q_1}}, \gtwo{\chi^{-q_2},
    \ldots, 1, \ldots, \chi^{q_2}}$, for some randomly picked
  $\chi \in \FF_p$, the assumption requires that $\adv$ cannot compute $\chi$. That is
	\[
    \condprob{\chi = \adv(\gone{\chi^{-q_1}, \ldots, 1, \ldots,
        \chi^{q_1}}, \gtwo{\chi^{-q_2}, \ldots, 1, \ldots, \chi^{q_2}
      })}{\chi \sample \FF_p} \leq \negl.
	\]
\end{definition}

\begin{definition}[$(q_1, q_2)\mhyph\uldlog$ assumption]\label{def:uldlog}
	Let $\adv$ be a $\ppt$ adversary that gets oracle access to $\initU$ with internal algorithms $(\kgen_{\ldlog}, \upd_{\ldlog}, \verifyCRS)$, where $\kgen_{\ldlog}$ and $\upd_{\ldlog}$ are defined as follows:
	\begin{itemize}
		\item $\kgen_\ldlog(\secpar)$ samples $\chi \sample \FF_p$ and defines 
		$\Ch:=(\gone{\chi^{-q_1}, \ldots, 1, \chi, \ldots,
			\chi^{q_1}}, \gtwo{\chi^{-q_2}, \ldots, 1, \chi, \ldots, \chi^{q_2}
		})$.
		\item $\upd_\ldlog(\Ch, \{\rho_j \}_{j=1}^n)$ 
		parses $\Ch$ as $\left( \gone{\smallset{A_i}_{i = -q_1}^{q_1}},
		\gtwo{\smallset{B_i}_{i = -q_2}^{q_2}} \right)$, samples
		$\widetilde{\chi} \sample \FF_p$, and defines
		$\widetilde{\Ch} := 
		\left( \gone{\smallset{\widetilde{\chi}^i A_i}_{i = -q_1}^{q_1}},
		\gtwo{\smallset{\widetilde{\chi}^i B_i}_{i = -q_2}^{q_2}} \right)$.
	\end{itemize}
	Then
	\[
	\prob{\bar{\chi} \gets \adv^{\initU}(\secpar)} \leq \negl,
	\]
	where $\left( \gone{\smallset{\bar{\chi}^i}_{i = -q_1}^{q_1}},
	\gtwo{\smallset{\bar{\chi}^i}_{i = -q_2}^{q_2}} \right)$ is the finalized challenge.
\end{definition}

\subsection{\sonic{} Protocol Rolled-out}
In this section we present $\sonic$'s constraint system and algorithms. Reader
familiar with them may jump directly to the next section.

 \begin{figure}[h!]
 \centering
 	\begin{pcvstack}[center,boxed]
 		\begin{pchstack}
 			\procedure{$\kgen(\secparam, \maxdeg)$} {
 				\alpha, \chi \sample \FF^2_p \\ [\myskip]
 				\pcreturn \gone{\smallset{\chi^i}_{i = -\multconstr}^{\multconstr},
           \smallset{\alpha \chi^i}_{i = -\multconstr, i \neq
             0}^{\multconstr}},\\
         \pcind \gtwo{\smallset{\chi^i, \alpha \chi^i}_{i =
             -\multconstr}^{\multconstr}}, \gtar{\alpha}\\
 				\hphantom{\hspace*{5.5cm}}
 		}

 			\pchspace

 			\procedure{$\com(\srs, \maxconst, \p{f}(X))$} {
 				\p{c}(X) \gets \alpha \cdot X^{\dconst - \maxconst} \p{f}(X) \\ [\myskip]
 				\pcreturn \gone{c} = \gone{\p{c}(\chi)}\\ [\myskip]
 				\hphantom{\pcind \pcif \sum_{i = 1}^{\abs{\vec{z}}} r_i \cdot
           \gone{\sum_{j = 1}^{t_j} \gamma_i^{j - 1} c_{i, j} - \sum_{j = 1}^{t_j}
             s_{i, j}} \bullet \gtwo{1} + } }
 		\end{pchstack}
 		% \pcvspace

 		\begin{pchstack}
 			\procedure{$\open(\srs, z, s, f(X))$}
 			{
 				\p{o}(X) \gets \frac{\p{f}(X) - \p{f}(z)}{X - z}\\ [\myskip]
 				\pcreturn \gone{\p{o}(\chi)}\\ [\myskip]
 				\hphantom{\hspace*{5.5cm}}
 			}

 			\pchspace

 			\procedure{$\verify(\srs, \maxconst, \gone{c}, z, s, \gone{\p{o}(\chi)})$}
       {
         \pcif \gone{\p{o}(\chi)} \bullet \gtwo{\alpha \chi} + \gone{s - z
         \p{o}(\chi)} \bullet \gtwo{\alpha} = \\ [\myskip] \pcind \gone{c}
         \bullet \gtwo{\chi^{- \dconst + \maxconst}} \pcthen  \pcreturn 1\\
         [\myskip]
         \rlap{\pcelse \pcreturn 0.} \hphantom{\pcind \pcif \sum_{i =
             1}^{\abs{\vec{z}}} r_i \cdot \gone{\sum_{j = 1}^{t_j} \gamma_i^{j -
               1} c_{i, j} - \sum{j = 1}^{t_j} s_{i, j}} \bullet \gtwo{1} + } }
 		\end{pchstack}
 	\end{pcvstack}

 	\caption{$\PCOMs$ polynomial commitment scheme.}
 	\label{fig:pcoms}
 \end{figure}



\oursubsub{The Constraint System}
\label{sec:sonic_constraint_system}
\cref{fig:pcoms} presents a variant of KZG~\cite{AC:KatZavGol10} polynomial commitment schemes used in \sonic{}. \sonic's system of constraints composes of three $\multconstr$-long vectors
$\va, \vb, \vc$ which corresponds to left and right inputs to multiplication
gates and their outputs. It hence holds $\va \cdot \vb = \vc$.

There is also $\linconstr$ linear constraints of the form
\[
  \va \vec{u_q} + \vb \vec{v_q} + \vc \vec{w_q} = k_q,
\]
where $\vec{u_q}, \vec{v_q}, \vec{w_q}$ are vectors for the $q$-th linear
constraint with instance value $k_q \in \FF_p$. Furthermore define polynomials
\begin{equation}
  \begin{split}
    \p{u_i}(Y) & = \sum_{q = 1}^\linconstr Y^{q + \multconstr} u_{q, i}\,,\\
    \p{v_i}(Y) & = \sum_{q = 1}^\linconstr Y^{q + \multconstr} v_{q, i}\,,\\
  \end{split}
  \qquad
  \begin{split}
    \p{w_i}(Y) & = -Y^i - Y^{-i} + \sum_{q = 1}^\linconstr Y^{q +
      \multconstr} w_{q, i}\,,\\
    \p{k}(Y) & = \sum_{q = 1}^\linconstr Y^{q + \multconstr} k_{q}.
  \end{split}
\end{equation}

$\sonic$ constraint system requires that
\begin{align}
  \label{eq:sonic_constraint}
  \vec{a}^\top \cdot \vec{\p{u}} (Y) + \vec{b}^\top \cdot \vec{\p{v}} (Y) +
  \vec{c}^\top \cdot \vec{\p{w}} (Y) + \sum_{i = 1}^{\multconstr} a_i b_i (Y^i +
  Y^{-i}) - \p{k} (Y) = 0.
\end{align}

In \sonic{} we will use commitments to the following polynomials.
\begin{align*}
  \pr(X, Y) & = \sum_{i = 1}^{\multconstr} \left(a_i X^i Y^i + b_i X^{-i} Y^{-i}
              + c_i X^{-i - \multconstr} Y^{-i - \multconstr}\right) \\
  \p{s}(X, Y) & = \sum_{i = 1}^{\multconstr} \left( u_i (Y) X^{-i} +
                v_i(Y) X^i + w_i(Y) X^{i + \multconstr}\right)\\
  \pt(X, Y) & = \pr(X, 1) (\pr(X, Y) + \p{s}(X, Y)) - \p{k}(Y)\,.
\end{align*}

Polynomials $\p{r} (X, Y), \p{s} (X, Y), \p{t} (X, Y)$ are designed such that
$\p{t} (0, Y) = \vec{a}^\top \cdot \vec{\p{u}} (Y) + \vec{b}^\top \cdot
\vec{\p{v}} (Y) + \vec{c}^\top \cdot \vec{\p{w}} (Y) + \sum_{i =
  1}^{\multconstr} a_i b_i (Y^i + Y^{-i}) - \p{k} (Y) $. That is, the prover is
asked to show that $\p{t} (0, Y) = 0$, cf.~\cref{eq:sonic_constraint}.

Furthermore, the commitment system in $\sonic$ is designed such that it is
infeasible for a $\ppt$ algorithm to commit to a polynomial with non-zero
constant term.

\oursubsub{Algorithms Rolled out}
\ourpar{$\sonic$ SRS generation $\kgen(\REL)$.} The SRS generating algorithm picks
randomly $\alpha, \chi \sample \FF_p$ and outputs
	\[
      \srs = \left( \gone{\smallset{\chi^i}_{i = -\dconst}^{\dconst},
          \smallset{\alpha \chi^i}_{i = -\dconst, i \neq 0}^{\dconst}},
        \gtwo{\smallset{\chi^i, \alpha \chi^i}_{i = - \dconst}^{\dconst}},
        \gtar{\alpha} \right)
	\]
\ourpar{$\sonic$ prover $\prover(\srs, \inp, \wit=\va, \vb, \vc)$.}
\begin{description}
\item[Message 1] The prover picks randomly randomizers
  $c_{\multconstr + 1}, c_{\multconstr + 2}, c_{\multconstr + 3}, c_{\multconstr
    + 4} \sample \FF_p$. Sets
  $\pr(X, Y) \gets \pr(X, Y) + \sum_{i = 1}^4 c_{\multconstr + i} X^{- 2
    \multconstr - i}$. Commits to $\pr(X, 1)$ and outputs
  $\gone{r} \gets \com(\srs, \multconstr, \pr(X, 1))$.  Then it computes challenge $y = \ro(\tzkproof[0..1])$.
\item[Message 2] $\prover$ commits to $\pt(X, y)$ and outputs
  $\gone{t} \gets \com(\srs, \dconst, \pt(X, y))$. Then it gets a challenge $z = \ro(\tzkproof[0..2])$.
\item[Message 3] The prover computes commitment openings. That is, it outputs
  \begin{align*}
    \gone{o_a} & = \open(\srs, z, \pr(z, 1), \pr(X, 1)) \\
    \gone{o_b} & = \open(\srs, y z, \pr(y z, 1), \pr(X, 1)) \\
    \gone{o_t} & = \open(\srs, z, \pt(z, y), \pt(X, y)) 
  \end{align*}
  along with evaluations $a' = \pr(z, 1), b' = \pr(y, z), t' = \pt(z, y)$.  Then it
  engages in the signature of correct computation playing the role of the
  helper, i.e.~it commits to $\p{s}(X, y)$ and sends the commitment $\gone{s}$, commitment opening
  \begin{align*}
    \gone{o_s} & = \open(\srs, z, \p{s}(z, y), \p{s}(X, y)), \\
  \end{align*} and $s'=\p{s}(z, y)$. 
%
  Then
  it obtains a challenge $u = \ro(\tzkproof[0..3])$.
\item[Message 4] For the next message the prover computes
  $\gone{c} \gets \com(\srs, \dconst, \p{s}(u, Y))$ and
  computes commitments' openings
  \begin{align*}
    \gone{w} & = \open(\srs, u, \p{s}(u, y), \p{s}(X, y)), \\
    \gone{q_y} & = \open(\srs, y,\p{s}(u, y), \p{s}(u, Y)),
  \end{align*}
  and returns $\gone{w}, \gone{q_y}, s = \p{s}(u, y)$. Eventually the prover gets the last challenge
  $z' = \ro(\tzkproof[0..4])$.
\item[Message 5] For the final message, $\prover$ computes opening
  $\gone{q_{z'}} = \open(\srs, z', \p{s}(u, z'), \p{s}(u, X))$ and outputs $\gone{q_{z'}}$.
\end{description}

\ourpar{$\sonic$ verifier $\verifier(\srs, \inp, \zkproof)$.} The verifier
in \sonic{} runs as subroutines the verifier for the polynomial commitment. That
is it sets $t' = a'(b' + s') - \p{k}(y)$ and checks the following:
\begin{equation*}
  \begin{split}
    &\PCOMs.\verifier(\srs, \multconstr, \gone{r}, z, a', \gone{o_a}), \\
    &\PCOMs.\verifier(\srs, \multconstr, \gone{r}, y z, b', \gone{o_b}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{t}, z, t', \gone{o_t}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{s}, z, s', \gone{o_s}),\\
  \end{split}
  \qquad
  \begin{split}
    &\PCOMs.\verifier(\srs, \dconst, \gone{s}, u, s, \gone{w}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{c}, y, s, \gone{q_y}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{c}, z', \p{s}(u, z'), \gone{q_{z'}}),
  \end{split}
\end{equation*}
and accepts the proof iff all the checks holds. Note that the value
$\p{s}(u, z')$ that is recomputed by the verifier uses separate challenges $u$
and $z'$. This enables the batching of many proof and outsourcing of this
part of the proof to an untrusted helper.

\subsection{Unique Opening Property of $\PCOMs$}
\begin{lemma}
\label{lem:pcoms_unique_op}
$\PCOMs$ has the unique opening property in the AGM. 
\end{lemma}
\begin{proof}
Let 
$z \in \FF_p$ be the attribute the polynomial is evaluated at,
$\gone{c} \in \GRP$ be the commitment,  
$s \in \FF_p$ the evaluation value, and 
$o \in \GRP$ be the commitment opening. 
We need to show that for every $\ppt$ adversary $\adv$ probability
\[
  \Pr \left[
    \begin{aligned}
      & \verify(\srs, \gone{c}, z, s, \gone{o}) = 1, \\
      & \verify(\srs, \gone{c}, z, \tilde{s}, \gone{\tilde{o}}) = 1
    \end{aligned}
    \,\left|\, \vphantom{\begin{aligned}
          & \verify(\srs, \gone{c}, z, s, \gone{o}),\\
          & \verify(\srs, \gone{c}, z, s, \gone{\tilde{o}}) \\
          &o \neq \tilde{o})
		\end{aligned}}
      \begin{aligned}
        %& \srs \gets \kgen(\secparam, \maxdeg), \\
        & (\gone{c}, z, s, \gone{o}, \gone{\tilde{o}}) \gets \adv^{\initU}(1^\secpar, \maxdeg)
      \end{aligned}
    \right.\right]
  % \leq \negl.
\]
is at most negligible.

As noted in \cite[Lemma 2.2]{EPRINT:GabWilCio19} it is enough to upper bound the
probability of the adversary succeeding against the ideal verifier, who verifies equality between polynomials.

For a polynomial $f$, its degree upper bound $\maxconst$, evaluation point $z$,
evaluation result $s$, and opening $\gone{o(X)}$ the ideal verifier checks that
\begin{equation}
  \alpha (X^{\dconst - \maxconst}f(X) \cdot X^{-\dconst + \maxconst} -  s) \equiv \alpha \cdot o(X) (X - z)\,,
\end{equation}
what is equivalent to 
\begin{equation}
	f(X) -  s \equiv o(X) (X - z)\,.
	\label{eq:pcoms_idealised_check}
\end{equation}
Since $o(X)(X - z) \in \FF_p[X]$ then from the uniqueness of polynomial
composition, there is only one $o(X)$ that fulfills the equation above.
\qed
\end{proof}

\subsection{Unique Response Property}
The unique response property of $\sonicprotfs$ follows from the unique opening
property of the polynomial commitment scheme $\PCOMs$.
\begin{lemma}
\label{lem:sonicprot_ur}
If a polynomial commitment scheme $\PCOMs$ is evaluation binding with security loss $\epsbind (\secpar)$ and has unique openings property with security loss $\epsop(\secpar)$,\COMMENT{ and $(\dconst, \dconst)$-$\uldlog$ problem is $\epsuldlog (\secpar)$-hard,} then $\sonicprotfs$ is $\ur{2}$ against algebraic adversaries with security loss
  \[
    2 \cdot \epsbinding (\secpar) + \epsop (\secpar).
  \]
\end{lemma}

\begin{proof}
  Let $\adv$ be an algebraic adversary tasked to break the $\ur{2}$-ness of
  $\sonicprotfs$. We note that to show $\ur{2}$-ness is is enough to show that the first prover's message determines, along with the verifiers challenges, the rest of it. 
  % This is done by game hops. In the games, the adversary outputs two proofs 
  We denote by $\zkproof^0$ and $\zkproof^1$ the two proofs for the same statement the adversary outputs.
  To distinguish polynomials and commitments which an honest prover sends in the
  proof from the polynomials and commitments computed by the adversary we write the latter using indices $0$ and $1$ (two indices as we have two transcripts), e.g.~to describe the quotient polynomial provided by the adversary we write $\p{t}^0$ and   $\p{t}^1$ instead of $\p{t}$ as in the description of the protocol.

  We note that since the unique response property requires from $\zkproof^{0}$ and $\zkproof^{1}$ that the first place they possibly differ is the $3$-th prover's message, then the challenge $z$, that is picked by the adversary after the $2$-rd message is the same in both transcripts. This challenge determines the evaluation point of polynomials $\p{r}(X, 1), \p{t}(X, y)$ which commitments are already sent.

  In its third message, the prover provides evaluations of these polynomials along with their openings at $z$ or $yz$. Note that the adversary can output two accepting proofs that differ on their third message only if it  manages to break evaluation binding of one of the opening. Since the commitment scheme is evaluation binding with security loss $\epsbinding (\secpar)$, the adversary can make $\zkproof^{0}$ and $\zkproof^{1}$ differ on the third message with probability at most $\epsbinding (\secpar) $. 

  Similarly, in its fourth message, the prover provides an evaluation at $u$ of polynomial $\p{s}(X, y)$, an evaluation at $y$ of $\p{s} (u, Y)$, and the corresponding openings. Note that the adversary can output two accepting proofs that differ on their fourth message only if it manages to break evaluation binding of one of the opening. Since the commitment scheme is evaluation binding with security loss $\epsbinding (\secpar)$, the adversary can make $\zkproof^{0}$ and $\zkproof^{1}$ differ on the fourth message with probability at most $\epsbinding (\secpar) $. 

  Next, assume that the transcripts are the same up to the fourth message, but differ at the fifth. In that message, the adversary provides openings of the evaluations. Since the unique opening property, the adversary can open the valid evaluation of a polynomial to two different values with probability at most $\epsop (\secpar)$.%, which is upper-bounded by $\epsuldlog (\secpar)$.

  By the union bound, the adversary is able to break the unique response property with probability upper bounded by $2 \epsbinding (\secpar) + \epsop (\secpar)$.
\iffalse
  \michals{30.4}{Old proof starts here}

  \ncase{Game 0} 
  \ngame{0} In this game, the adversary additionally wins if it provides two transcripts that match on all $5$ messages sent by the prover.
  In this game the adversary cannot win.

  \ngame{1} This game is identical to Game $\game{0}$ except that now the
  adversary additionally wins if it provides two transcripts that matches on the first four
  messages of the proof.

  \ncase{Game 0 to Game 1} We show that the probability that $\adv$
  wins in one game but does not in the other is negligible.  Observe that in
  after its $4$-th message, the adversary is given a challenge $z'$ and has to open
  commitment to $\p{s} (u, z')$. Hence, to be able to give two different
  openings in its $5$-th message, $\adv$ has to break the unique opening property of the
  KZG commitment scheme which happens with probability $\epsop (\secpar)$ tops.

  \ngame{2} This game is identical to Game $\game{1}$ except that now the
  adversary additionally wins if it provides two transcripts that matches on the
  first three messages of the proof.

  \ncase{Game 2 to Game 3} In its $4$-th message the adversary computes evaluation
  $s = \p{s} (u, y)$ and the corresponding openings $\gone{w}, \gone{q_y}$. The adversary
  cannot provide two different evaluations for the committed polynomials, since that would
  require breaking the evaluation binding property, which happens (by the union bound)
  with probability at most $2 \cdot \epsbind (\secpar)$. Also, the adversary cannot provide two
  different yet valid opening except probability $2 \cdot \epsop (\secpar)$

  Hence, the probability that adversary wins in one game but does not in the
  other is upper-bounded by $2 \cdot (\epsbind (\secpar) + \epsop (\secpar))$

  \ngame{4} This game is identical to Game $\game{3}$ except that now the
  adversary additionally wins if it provides two transcripts that match on the
  first two messages of the proof.

  \ncase{Game 3 to Game 4} In its $3$-rd message the adversary computes $4$ polynomial
  evaluations and their openings. It also sends commitment to $\p{s} (X, y)$ which is a
  signature of correct computation.

  Probability that the adversary provides different evaluations or polynomial openings is
  upper bounded by $4 \cdot (\epsop (\secpar) + \epsbind (\secpar))$. Since the polynomial
  commitment scheme is deterministic, if commitment to $\p{s^0} (X, y)$ does not equal
  commitment to $\p{s^1} (X, y)$, then at least one of these values has been computed
  incorrectly. Probability that the adversary outputs an accepting proof, where signature
  of correct computation has been computed incorrectly is upper-bounded by $\epss
  (\secpar) + \epsdlog (\secpar)$, cf.~\cref{lem:plonkprot_ur}.

  \ncase{Game 5}  This game is identical to Game $\game{4}$ except that now the
  adversary additionally wins if it provides two transcripts that match on the
  first messages of the proof.

  \ncase{Game 4 to Game 5} In its second message the adversary commits to polynomial
  $\p{t} (X, y)$. Since the commitment scheme is deterministic, probability that adversary
  outputs accepting proofs where commitment to $\p{t^0} (X, y)$ does not equal commitment
  to $\p{t^1} (X)$ is upper-bounded by $\epss (\secpar) + \epsdlog (\secpar)$, cf.~\cref{lem:plonkprot_ur}.

  \ncase{Conclusion} Taking all the games together, the probability that $\adv$ wins
  in Game 5 is upper-bounded by
  \[
    3 \cdot \epsop (\secpar) + 2 \cdot (\epsbind (\secpar) + \epss (\secpar) +
    \epsdlog (\secpar)).
  \]
  \fi
  \qed
\end{proof}

\subsection{Rewinding-Based Knowledge Soundness}
\begin{lemma}
	\label{lem:sonicprot_ss}
  $\sonicprotfs$ is $(2, \noofc + 1)$-rewinding-based knowledge sound against algebraic adversaries who make up to $q$ random oracle queries with security loss 
  \[
    \epscss(\secpar,\accProb, q) \leq \left(1 - \frac{\accProb - (q + 1) \left( \frac{\noofc}{p}\right)}{1 - \frac{\noofc}{p}}\right) + (\noofc + 1) \cdot \epsuldlog (\secpar)\,,
  \]
	Here $\accProb$ is a probability that the adversary outputs an accepting proof, and $\epsuldlog(\secpar)$ is the security of $(\maxdeg, \maxdeg)$-$\uldlog$ assumption.
\end{lemma}

% 	$\sonicprot$ is $(2, \noofc + 1)$-computational special sound with security loss $(\epst (\accProb, \secpar), \epss(\secpar))$ against
% 	algebraic adversaries, where
%   \[
%     \epst(\accProb, \secpar) \leq \frac{\accProb - (q + 1) \epsid (\secpar)}{1 - \epsid (\secpar)}\,,
%   \]
%   and
% 	\[
% 	  \epss(\secpar) \leq \epsid(\secpar) + \epsldlog(\secpar) \,.
% 	\]
% 	Here $\accProb$ is a probability that the adversary outputs an accepting proof, $q$ is the upper bound for a number of random oracle queries the adversary makes, $\epsid(\secpar)$ is a soundness error of the idealized verifier, and $\epsldlog(\secpar)$ is security of $(\dconst, \dconst)$-$\ldlog$ assumption.
% \end{lemma}


Let $\adv^{\ro, \initU}(\secparam; r)$ be the adversary who outputs $(\inp, \zkproof)$ such that $\sonicprotfs.\verifier$ accepts the proof. Let $\tdv$ be the tree-building algorithm of \cref{lem:attema} that outputs a tree $\tree$, and let $\extcss$ be an extractor that given the tree output by $\tdv$ reveals the witness for $\inp$. The main idea of the proof is to show that an adversary who breaks rewinding-based knowledge soundness can be used to break a $\uldlog$-problem instance. The proof goes by game hops. Note that since the tree branches after $\adv$'s $2$-nd message, the instance $\inp$, commitments $\gone{\p{r} (\chi, 1), \p{t} (\chi, y)}$, and challenge $y$ are the same in all the transcripts. Also, the tree branches after the second adversary's message where the challenge $z$ is presented, thus tree $\tree$ is built using different values of $z$.	We consider the following games.

  \ncase{Game 0} %
  In this game, the adversary wins if it outputs a valid instance--proof pair $(\inp, \zkproof)$, and the extractor $\extcss$ does not manage to output a witness $\wit$ such that $\REL (\inp, \wit)$ holds.

  \ncase{Game 1} %
  In this game, the environment aborts the game if the tree building algorithm $\tdv$ fails in building a tree of accepting transcripts $\tree$. 

  \ncase{Game 0 to Game 1} %
  By \cref{lem:attema} probability that Game 1 is aborted, while Game 0 is not, is, at most
  \[
    1 - \frac{\accProb - (q + 1) \left( \frac{\noofc}{p} \right)} {1 - \frac{\noofc }{p}} \,.
\]

  \ncase{Game 2} %
  In this game the environment additionally aborts if at least one of its proofs in $\tree$ is not accepting by an ideal verifier.

  \ncase{Game 1 to Game 2} % 
  As usual, we show a reduction that breaks an instance of a $\uldlog$ assumption when Game 2 is aborted, while Game 1 is not.

  Let $\rdvuldlog$ be a reduction that gets as input an $(\maxdeg, \maxdeg)$-$\uldlog$ instance $\gone{\chi^{-\maxdeg}, \ldots, 1, \ldots, \chi^{\maxdeg}}, \gtwo{\chi^{-\maxdeg}, \ldots, 1, \ldots, \chi^{\maxdeg}}$. Then it can update the instance to another one $\gone{\chi'^{-\maxdeg}, \ldots, 1, \ldots, \chi'^{\maxdeg}}, \gtwo{\chi'^{-\maxdeg}, \ldots, 1, \ldots, \chi'^{\maxdeg}}$. Eventually, the reduction outputs $\chi'$.
	%
	The reduction $\rdvuldlog$ proceeds as follows.
	First, it builds $\adv$'s SRS $\srs$ using the input $\uldlog$ instance. Then it processes the adversary's update query by adding it to the list $\Qsrs$ and passing it to its own update oracle getting instance $\gone{\chi'^{-\maxdeg}, \ldots, 1, \ldots, \chi'^{\maxdeg}}, \gtwo{\chi'^{-\maxdeg}, \ldots, 1, \ldots, \chi'^{\maxdeg}}$. The updated SRS $\srs'$ is then computed and given to $\adv$. $\rdvuldlog$ also takes care of the random oracle queries made by $\adv$. It picks their answers honestly and writes them in $\Qro$. The reduction then starts $\tdv(\srs, \adv, r, \Qro, \Qsrs)$.
	
  Let $(1, \tree)$ be the output returned by $\tdv$. Let $\inp$ be a relation proven in $\tree$.  Consider a transcript $\zkproof \in \tree$ such that $\vereq_{\inp, \zkproof}(X) \neq 0$, but $\vereq_{\inp, \zkproof}(\chi') = 0$. Since $\adv$ is algebraic, all group elements included in $\tree$ are extended by their representation as a combination of the input $\GRP_1$-elements. Hence, all coefficients of the verification equation polynomial $\vereq_{\inp, \zkproof}(X)$ are known. 
  Eventually, the reduction finds $\vereq_{\inp, \zkproof}(X)$ zero points and returns $\chi'$ which is one of them.
    
  Hence, the probability that the adversary wins in Game 2 but does not win in Game 1 is upper-bounded by $(\noofc + 1) \cdot \epsuldlog (\secpar)$.

  \ncase{Conclusion}
  Note that the adversary can win in Game 2 only if $\tdv$ manages to produce a tree of accepting transcript $\tree$, such that each of the transcripts in $\tree$ is accepting by an ideal verifier. Note that since $\tdv$ produces $(\noofc + 1)$ accepting transcripts for different challenges $z$, it obtains the same number of different evaluations of polynomial $\p{t} (z, y)$ what allows to extract the witness, cf.~\cite{CCS:MBKM19}.

  Hence, the probability that the adversary wins in Game 0 is upper-bounded by 
  \[
    \epscss(\secpar,\accProb, q) \leq \left(1 - \frac{\accProb - (q + 1) \left( \frac{\noofc}{p} \right)}{1 - \frac{\noofc}{p}}\right) + (\noofc + 1) \cdot\epsuldlog (\secpar)\,. 
  \]

\subsection{Trapdoor-Less Zero-Knowledge of Sonic}
\michals{9.06.23}{Get back to the previous version of the proof}
\begin{lemma}
\label{lem:sonic_hvzk}
$\sonicprotfs$ is 2-programmable trapdoor-less zero-knowledge.
\end{lemma}
\begin{proof}
  The simulator proceeds as follows.
  \begin{enumerate}
  \item Pick randomly vectors $\vec{a}$, $\vec{b}$ and set
    \begin{equation}
      \label{eq:ab_eq_c}
      \vec{c} = \vec{a} \cdot \vec{b}. 
    \end{equation}
  \item Pick randomizers $c_{\multconstr + 1}, \ldots, c_{\multconstr + 4}$,
    honestly compute polynomials $\p{r}(X, Y), \p{s}(X, Y), \p{r'}(X, Y) = (\p{r}(X, Y) + \p{s} (X, Y))$.
  \item Compute polynomial $\p{t} (X, Y) = \p{r} (X, 1) \p{r'}(X, Y) - \p{k} (Y)$.
  \item Output commitment $\gone{r} \gets \com(\srs, \multconstr, \p{r} (X, 1))$ and challenge $y$, such that  $\p{t} (0, y) = 0$. 
  % \item Output commitment $\gone{t} = \com (\srs, \dconst, \p{t} (X, y))$ and
  % challenge $z$.
  % \item Compute
  %   \begin{align*}
  %     & a' = \p{r}(z, 1),\\
  %     & b' = \p{r}(z, y),\\
  %     & s' = \p{s}(z, y).
  %   \end{align*} 
  % % \item Output polynomial $\p{t}(X, Y)$
  \item Continue following the protocol.
  \end{enumerate}
\michals{16.06}{Change the discussion below to accommodate for the new simulation strategy}
\michals{28.07}{We need to argue that $y$ looks random}
  We note that the simulation is perfect. 
  
  \markulf{28.07}{Due to the randomization, evaluations are equality distributed in the real and the simulated proof. we should check this by enumerating evaluation ($r(\chi,1), t(\chi, y), r(z,1), r(yz,1), t(z,y)$), where $r(z,1), r(yz,1)$ determine $t(z,y)$ and explaining randomization better. As $\vec{a}$ and $\vec{b}$ are sampled at random, all values $y$ are equally likely to be roots of $t(0,Y)$. I actually wonder whether we can pick witnesses in a way that makes this more obvious.}
  
  This comes since all polynomials are computed following the protocol, only $\gamma$ is programmed for the simulated proof. For 
  polynomial $\p{t} (X, Y)$ we observe that in a case of both real and simulated
  proof the verifier only learns commitment $\gone{t} = \p{t} (\chi, y)$ and
  evaluation $t' = \p{t} (z, y)$. Since the simulator picks $\p{t} (X, Y)$ such
  that 
  \begin{align*}
      \p{t} (X, y) = \p{r} (X, 1) (\p{r}(X, y) + \p{s} (X, y)) - \p{k} (Y),
  \end{align*}
  values of $\gone{t}$ are equal in both proofs.
  Furthermore, the simulator picks its polynomial such that $\p{t}(0, y) = 0$,
  hence it does not need the trapdoor to commit to it. (Note that the proof
  system's SRS does not allow to commit to polynomials which have non-zero
  constant term). \qed
\end{proof}
\begin{remark} 
  As noted in \cite{CCS:MBKM19}, $\sonic$ is statistically subversion zero-knowledge (Sub-ZK). As noted in \cite{AC:ABLZ17short}, one way to achieve
  subversion zero-knowledge is to utilize an extractor that extracts a SRS
  trapdoor from a SRS-generator. Unfortunately, a NIZK made subversion
  zero-knowledge by this approach cannot achieve perfect Sub-ZK as one has to
  count in the probability of extraction failure. However, with the simulation
  presented in \cref{lem:sonic_hvzk}, the trapdoor is not required for the
  simulator as it is able to simulate the execution of the protocol just by
  picking appropriate (honest) verifier's challenges. This result transfers to
  $\sonicprotfs$, where the simulator can program the random oracle to provide
  challenges that fits it.
\end{remark}


\subsection{Simulation Extractability of $\sonicprotfs$}
Since \cref{lem:sonicprot_ur,lem:sonicprot_ss,lem:sonic_hvzk} hold, $\sonicprotfs$ is $\ur{2}$, rewinding-based knowledge sound and trapdoor-less zero-knowledge. We now make use
of \cref{thm:se} and show that $\sonicprotfs$ is simulation-extractable as defined in \cref{def:simext}.

\begin{corollary}[Simulation extractability of $\sonicprotfs$]
  \label{thm:sonicprotfs_se}
  $\sonicprotfs$ is \emph{updatable simulation-extractable} against any $\ppt$ adversary $\advse$ who makes up to $q$ random oracle queries and returns an accepting proof with probability at least $\accProb$ with extraction failure probability 
\[
  \epsse(\secpar, \accProb, q) \leq \left(1 - \frac{\accProb - \epsur (\secpar) - (q + 1) \epserr (\secpar)} {1 - \epserr (\secpar)}\right) + (\noofc + 1) \cdot \epsuldlog (\secpar) ,
\]
where $\epserr (\secpar) = \frac{\noofc}{p}$, $p$ is the size of the field, and $\noofc$ is the number of constrains in the circuit. 
\end{corollary}

%%% Local Variables:
%%% mode: latex 
%%% TeX-master: "main"
%%% End:
